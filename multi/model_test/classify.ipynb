{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# BiLSTM 多分类模型 - 批量预测\n",
        "\n",
        "加载训练好的模型，对ARG序列进行类别分类\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from Bio import SeqIO\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 配置\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================== 路径配置（请修改）==================\n",
        "MODEL_PATH = \"/path/to/well-trained/bilstm_multi_xxx.pth\"  # 训练保存的模型\n",
        "INPUT_DIR = \"/path/to/predicted_ARGs\"                      # 二分类预测出的ARG文件夹\n",
        "OUTPUT_CSV = \"./classification_results.csv\"                # 输出结果\n",
        "\n",
        "# 设备\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 模型与数据处理定义\n",
        "\n",
        "**注意**: 这里的定义必须与训练代码完全一致！\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 氨基酸编码字典（必须与训练一致）\n",
        "AMINO_ACIDS = 'ACDEFGHIKLMNPQRSTVWY'\n",
        "AA_DICT = {aa: i for i, aa in enumerate(AMINO_ACIDS)}\n",
        "AA_DICT.update({\n",
        "    'B': [AA_DICT['D'], AA_DICT['N']],\n",
        "    'Z': [AA_DICT['E'], AA_DICT['Q']],\n",
        "    'J': [AA_DICT['I'], AA_DICT['L']],\n",
        "    'X': 'ANY',\n",
        "    'PAD': 20\n",
        "})\n",
        "\n",
        "def one_hot_encode(sequence, max_length):\n",
        "    \"\"\"将氨基酸序列转换为one-hot编码\"\"\"\n",
        "    encoding = np.zeros((max_length, 21), dtype=np.float32)\n",
        "    for i in range(min(len(sequence), max_length)):\n",
        "        aa = sequence[i]\n",
        "        if aa in AA_DICT:\n",
        "            idx = AA_DICT[aa]\n",
        "            if isinstance(idx, list):\n",
        "                for j in idx:\n",
        "                    encoding[i, j] = 0.5\n",
        "            elif idx == 'ANY':\n",
        "                encoding[i, :20] = 0.05\n",
        "            else:\n",
        "                encoding[i, idx] = 1.0\n",
        "        else:\n",
        "            encoding[i, :20] = 0.05\n",
        "    if len(sequence) < max_length:\n",
        "        encoding[len(sequence):, 20] = 1.0\n",
        "    return encoding\n",
        "\n",
        "\n",
        "class BiLSTMClassifier(nn.Module):\n",
        "    \"\"\"BiLSTM + Global Pooling 多分类模型（必须与训练一致）\"\"\"\n",
        "    \n",
        "    def __init__(self, config, num_classes):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=config['embedding_size'],\n",
        "            hidden_size=config['hidden_size'],\n",
        "            num_layers=config['num_layers'],\n",
        "            batch_first=True,\n",
        "            bidirectional=True,\n",
        "            dropout=config['dropout'] if config['num_layers'] > 1 else 0\n",
        "        )\n",
        "        self.dropout = nn.Dropout(config['dropout'])\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(config['hidden_size'] * 4, config['hidden_size']),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(config['dropout']),\n",
        "            nn.Linear(config['hidden_size'], num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        output, _ = self.lstm(x)\n",
        "        max_pool, _ = torch.max(output, dim=1)\n",
        "        avg_pool = torch.mean(output, dim=1)\n",
        "        features = torch.cat([max_pool, avg_pool], dim=1)\n",
        "        return self.classifier(self.dropout(features))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 加载模型\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 加载模型（自动读取保存的配置）\n",
        "print(f\"Loading model from: {MODEL_PATH}\")\n",
        "checkpoint = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
        "\n",
        "# 从checkpoint中读取配置\n",
        "config = checkpoint['model_config']\n",
        "class_names = checkpoint['class_names']\n",
        "max_length = checkpoint['max_length']\n",
        "\n",
        "print(f\"Model config: {config}\")\n",
        "print(f\"Classes: {class_names}\")\n",
        "print(f\"Max length: {max_length}\")\n",
        "\n",
        "# 初始化并加载模型\n",
        "model = BiLSTMClassifier(config, len(class_names)).to(device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "print(\"Model loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 批量预测\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_batch(model, sequences, metadata, class_names, max_length):\n",
        "    \"\"\"处理一个Batch并返回结果\"\"\"\n",
        "    # 编码\n",
        "    encoded = np.array([one_hot_encode(seq, max_length) for seq in sequences])\n",
        "    inputs = torch.tensor(encoded, dtype=torch.float32).to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        logits = model(inputs)\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        max_probs, preds = torch.max(probs, dim=1)\n",
        "    \n",
        "    results = []\n",
        "    for i in range(len(preds)):\n",
        "        file_name, seq_id, seq_str = metadata[i]\n",
        "        pred_class = class_names[preds[i].item()]\n",
        "        prob = max_probs[i].item()\n",
        "        results.append({\n",
        "            'FileName': file_name,\n",
        "            'SequenceID': seq_id,\n",
        "            'PredictedClass': pred_class,\n",
        "            'Probability': prob,\n",
        "            'Sequence': seq_str\n",
        "        })\n",
        "    return results\n",
        "\n",
        "\n",
        "def run_classification():\n",
        "    \"\"\"批量分类\"\"\"\n",
        "    # 获取所有输入文件\n",
        "    files = glob.glob(os.path.join(INPUT_DIR, \"*.fasta\")) + \\\n",
        "            glob.glob(os.path.join(INPUT_DIR, \"*.faa\"))\n",
        "    print(f\"Found {len(files)} files to process\")\n",
        "    \n",
        "    all_results = []\n",
        "    batch_size = 256\n",
        "    batch_seqs = []\n",
        "    batch_meta = []\n",
        "    \n",
        "    for file_path in tqdm(files, desc=\"Processing\"):\n",
        "        try:\n",
        "            records = list(SeqIO.parse(file_path, \"fasta\"))\n",
        "            if not records:\n",
        "                continue\n",
        "            \n",
        "            file_name = os.path.basename(file_path)\n",
        "            \n",
        "            for record in records:\n",
        "                seq_str = str(record.seq).upper()\n",
        "                batch_seqs.append(seq_str)\n",
        "                batch_meta.append((file_name, record.id, seq_str))\n",
        "                \n",
        "                if len(batch_seqs) >= batch_size:\n",
        "                    results = process_batch(model, batch_seqs, batch_meta, class_names, max_length)\n",
        "                    all_results.extend(results)\n",
        "                    batch_seqs = []\n",
        "                    batch_meta = []\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {file_path}: {e}\")\n",
        "            continue\n",
        "    \n",
        "    # 处理剩余数据\n",
        "    if batch_seqs:\n",
        "        results = process_batch(model, batch_seqs, batch_meta, class_names, max_length)\n",
        "        all_results.extend(results)\n",
        "    \n",
        "    # 保存结果\n",
        "    df = pd.DataFrame(all_results)\n",
        "    df.to_csv(OUTPUT_CSV, index=False)\n",
        "    print(f\"\\nDone! Results saved to: {OUTPUT_CSV}\")\n",
        "    print(f\"Total sequences classified: {len(df)}\")\n",
        "    \n",
        "    # 打印统计\n",
        "    print(\"\\nClass distribution:\")\n",
        "    print(df['PredictedClass'].value_counts())\n",
        "    \n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 运行\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 运行分类\n",
        "results_df = run_classification()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
